{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !//usr/bin/env/python\n",
    "\n",
    "# -*- coding:utf-8 -*-\n",
    "import sys, json, time, calendar, re\n",
    "import urllib\n",
    "import collections as cl\n",
    "import codecs\n",
    "from os.path import join, dirname, abspath, exists\n",
    "from datetime import datetime\n",
    "from twitter import Twitter, OAuth\n",
    "from watson_developer_cloud import PersonalityInsightsV3\n",
    "from requests_oauthlib import OAuth1Session\n",
    "import config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "あなたのTwitter IDは？: fu_wo_msk\n",
      "どのTwitter IDとの相性を診断しますか？: mohamoha_min\n",
      "['fu_wo_msk', 'mohamoha_min']\n",
      "tweets-fu_wo_msk.jsonが生成されました\n",
      "analyzed-fu_wo_msk.jsonが存在します。既存のファイルで処理を続行します。\n",
      "tweets-mohamoha_min.jsonが生成されました\n",
      "analyzed-mohamoha_min.jsonが存在します。既存のファイルで処理を続行します。\n",
      "{'Openness': '53%', 'Conscientiousness': '96%', 'Extraversion': '66%', 'Agreeableness': '86%', 'Emotional range': '21%'}\n"
     ]
    }
   ],
   "source": [
    "# Twitter API 初期設定\n",
    "CK = config.get_consumer_key()\n",
    "CS = config.get_consumer_secret()\n",
    "AT = config.get_access_token()\n",
    "AS = config.get_access_secret()\n",
    "twitter = Twitter(auth=OAuth(AT, AS, CK, CS))\n",
    "\n",
    "# Watson Personality Insights API 初期設定\n",
    "UN = config.get_username()\n",
    "PS = config.get_password()\n",
    "personality_insights = PersonalityInsightsV3(version='2017-10-13', username=UN, password=PS)\n",
    "\n",
    "# APIからツイートを取ってくる\n",
    "def get_user_tweets(screen_name):\n",
    "    number_of_tweets = 0\n",
    "    count = 200\n",
    "    max_id = ''\n",
    "    tweets = []\n",
    "    a_timeline = twitter.statuses.user_timeline(screen_name=screen_name, count=count, include_rts='false', tweet_mode='extended')\n",
    "    # 取得件数500\n",
    "    while number_of_tweets <= 500:\n",
    "        for tweet in a_timeline:\n",
    "            number_of_tweets += 1\n",
    "            tweets.append(tweet['full_text'])\n",
    "            max_id = tweet['id']\n",
    "        # 取得件数より指定ユーザーのツイートが少ない場合\n",
    "        if tweets[-1] == tweets[-2]:\n",
    "            del tweets[-1]\n",
    "            break\n",
    "        a_timeline = twitter.statuses.user_timeline(screen_name=screen_name, count=count, max_id=max_id, include_rts='false', tweet_mode='extended')\n",
    "    return tweets\n",
    "\n",
    "# 余計な文字を省く・実体参照を文字に戻す\n",
    "def get_shaped_tweets(tweets_list):\n",
    "    shaped_tweets = []\n",
    "    rm_replie = re.compile(r'@([A-Za-z0-9_]+)')\n",
    "    rm_url = re.compile(r'https?://t.co/([A-Za-z0-9_]+)')\n",
    "    rm_hashtag = re.compile(r'#(\\w+)')\n",
    "    for tweet in tweets_list:\n",
    "        shape = rm_replie.sub('', tweet)\n",
    "        shape = rm_url.sub('', shape)\n",
    "        shape = rm_hashtag.sub('', shape)\n",
    "        shape = shape.replace('&gt;', '>').replace('&lt;', '<').replace('&amp;', '&').replace('\\n', ' ')\n",
    "        shaped_tweets.append(shape)\n",
    "    return shaped_tweets\n",
    "\n",
    "# P.I.に突っ込む体裁を整えてjson形式\"tweets.json\"に\n",
    "def tweets_conv_json(tweets_list, user):\n",
    "    file_name = 'tweets-' + user +'.json'\n",
    "    tweets_json = {}\n",
    "    tweets_json['contentItems'] = []\n",
    "    for tweet in tweets_list:\n",
    "        data = cl.OrderedDict()\n",
    "        data['content'] = tweet\n",
    "        data['contenttype'] = 'text/plain'\n",
    "        data['language'] = 'ja'\n",
    "        tweets_json['contentItems'].append(data)\n",
    "    with codecs.open(file_name, 'w', 'utf-8') as fw:\n",
    "        json.dump(tweets_json, fw, indent=4 ,ensure_ascii=False)\n",
    "    print(file_name + 'が生成されました')\n",
    "\n",
    "# 生成したtweets.jsonをもとにWatsonAPI呼び出し\n",
    "def get_insights_analytics(user):\n",
    "    in_file_name = 'tweets-' + user + '.json'\n",
    "    ex_file_name = 'analyzed-' + user + '.json'\n",
    "    with open(join(dirname(abspath('__file__')), in_file_name), encoding='utf-8_sig') as tweets_json:\n",
    "        profile = personality_insights.profile(\n",
    "            tweets_json.read(),\n",
    "            content_type='application/json',\n",
    "            raw_scores=True,\n",
    "            consumption_preferences=True\n",
    "        )\n",
    "        with codecs.open(ex_file_name, 'w', 'utf-8') as fw:\n",
    "            json.dump(profile, fw, indent=2)\n",
    "        print(ex_file_name + 'が生成されました')\n",
    "\n",
    "# big5のpercentileだけ抽出\n",
    "def get_big5(user):\n",
    "    file_name = 'analyzed-' + user + '.json'\n",
    "    with open(join(dirname(abspath('__file__')), file_name), 'r') as analyzed_json:\n",
    "        json_data = json.load(analyzed_json)\n",
    "        big5 = {}\n",
    "        for data in json_data['personality']:\n",
    "            big5[data['name']] = data['percentile']\n",
    "    return big5\n",
    "\n",
    "# big5の差を取り出す\n",
    "def get_big5_diff(data):\n",
    "    diffs = {}\n",
    "    for status in data[users[0]].keys():\n",
    "        diffs[status] = abs(data[users[0]][status] - data[users[1]][status])\n",
    "    return diffs\n",
    "\n",
    "# big5の差をわかりやすい数値に\n",
    "def diff_conv_percent(data):\n",
    "    diff_percents = {}\n",
    "    for status in data.keys():\n",
    "        diff_percents[status] = str(round(100 - data[status] * 100)) + '%'\n",
    "    return diff_percents\n",
    "\n",
    "# メイン処理部分(API使用回数をケチる処理込み)\n",
    "\n",
    "users = []\n",
    "users.append(input('あなたのTwitter IDは？: '))\n",
    "users.append(input('どのTwitter IDとの相性を診断しますか？: '))\n",
    "print(users)\n",
    "\n",
    "big5 = {}\n",
    "for user in users:\n",
    "    if exists(join(dirname(abspath('__file__')) , 'tweets-' + user + '.json')) == False:\n",
    "        tweets = get_user_tweets(user)\n",
    "        tweets = get_shaped_tweets(tweets)\n",
    "        tweets_conv_json(tweets, user)\n",
    "    else:\n",
    "        print('tweets-' + user + '.jsonが存在します。既存のファイルで処理を続行します。')\n",
    "    \n",
    "    if exists(join(dirname(abspath('__file__')) , 'analyzed-' + user + '.json')) == False:\n",
    "        get_insights_analytics(user)\n",
    "    else:\n",
    "        print('analyzed-' + user + '.jsonが存在します。既存のファイルで処理を続行します。')\n",
    "    big5[user] = get_big5(user)\n",
    "    \n",
    "big5_diff = get_big5_diff(big5)\n",
    "print(diff_conv_percent(big5_diff))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
